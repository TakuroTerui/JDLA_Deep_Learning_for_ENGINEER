{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "リカレントニューラルネットワーク.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCKKah+ICQfwGSTyDzbPNp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "6qWHKk0Fh-Bs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YleSm3zshmRY"
      },
      "outputs": [],
      "source": [
        "class SimpleRnnlm:\n",
        "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "        rn = np.random.randn\n",
        "\n",
        "        # 重みの初期化\n",
        "        embed_W = rn(V, D).astype('f')\n",
        "        rnn_Wx = rn(D, H).astype('f')\n",
        "        rnn_Wh = rn(H, H).astype('f')\n",
        "        rnn_b = np.zeros(H).astype('f')\n",
        "        affine_W = rn(H, V).astype('f')\n",
        "        affine_W = np.zeros(V).astype('f')\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = [\n",
        "            TimeEmbedding(embed_W),\n",
        "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b),\n",
        "            TimeAffine(affine_W, affine_b)\n",
        "        ]\n",
        "        self.loss_layer = TimeSoftmaxWithLoss()\n",
        "        self.rnn_layer = self.layer[1]\n",
        "\n",
        "        # すべての重みと勾配をリストにまとめる\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "    \n",
        "    def forward(self, xs, ts):\n",
        "        for layer in self.layers:\n",
        "            xs = layer.forward(xs)\n",
        "        loss = self.loss_layer.forward(xs, ts)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [\n",
        "            np.zeros_like(Wx),\n",
        "            np.zeros_like(Wh),\n",
        "            np.zeros_like(b),\n",
        "        ]\n",
        "        self.cache = None\n",
        "    \n",
        "    def forward(self, x, h_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
        "        h_next = np.tanh(t)\n",
        "\n",
        "        self.cache = (x, h_prev, h_next)\n",
        "        return h_next"
      ],
      "metadata": {
        "id": "Beh4Zk1lhwJo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeRNN:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [\n",
        "            np.zeros_like(Wx),\n",
        "            np.zeros_like(Wh),\n",
        "            np.zeros_like(b),\n",
        "        ]\n",
        "        self.layers = None\n",
        "        self.h, self.dh = None, None\n",
        "    \n",
        "    def forward(self, xs):\n",
        "        Wx, Wh, b = self.params\n",
        "        N, T, D = xs.shape\n",
        "        D, H = Wx.shape\n",
        "\n",
        "        self.layers = []\n",
        "        hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "        if self.h is None:\n",
        "            self.h = np.zeros((N, H), dtype='f')\n",
        "        \n",
        "        for t in range(T):\n",
        "            layer = RNN(*self.params)\n",
        "            self.h = layer.forward(xs[:, t, :], self.h)\n",
        "            hs[:, t, :] = self.h\n",
        "            self.layers.append(layer)\n",
        "        \n",
        "        return hs"
      ],
      "metadata": {
        "id": "a8TzOLahka0Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeAffine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        N, T, H = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        rx = x.reshape(N * T, -1)\n",
        "        out = np.dot(rx, W) + b\n",
        "        self.x = x\n",
        "        return out.reshape(N, T, -1)"
      ],
      "metadata": {
        "id": "QQxgFw9rlWFd"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}