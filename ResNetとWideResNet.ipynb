{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNetとWideResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMf4vbd2cNjg9VXl7at8xKy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rvGha77tDSZf"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "n8NuAIakDWoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 残差学習"
      ],
      "metadata": {
        "id": "Vb9JRJh-DYLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)"
      ],
      "metadata": {
        "id": "zX2Uol3pDbEN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "DKDBe0GCDckk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bottleneck ブロック"
      ],
      "metadata": {
        "id": "gLdnlL_iDiaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "metadata": {
        "id": "T9DozAPRDoA3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "ecaMASKCDqw5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### He の初期化"
      ],
      "metadata": {
        "id": "SivxTLX5DwXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### nn.init.kaiming_normal_"
      ],
      "metadata": {
        "id": "eY1_-Tt2Dz-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Normalization"
      ],
      "metadata": {
        "id": "FdYL2lloD3Bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WideResNet"
      ],
      "metadata": {
        "id": "AHXFAgRuD9Ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WideResNet の論文では深さではなく Residuak Block の幅を広げることが、深さを増やすことに比べてより効率的に性能を向上することができると主張しています"
      ],
      "metadata": {
        "id": "Mk4kC-ywEOx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 残差学習における性能改善"
      ],
      "metadata": {
        "id": "YvCx2iAGEBJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dropout による精度向上"
      ],
      "metadata": {
        "id": "rk6QFEzdEHEy"
      }
    }
  ]
}