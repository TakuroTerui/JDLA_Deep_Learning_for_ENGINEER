{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "全結合型ニューラルネットワーク.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSkaJbxO6OVBDGuCgig+je"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4LxEFqTv1VqZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(X):\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "def softmax(X):\n",
        "    X = X - np.max(X, axis=1, keepdims=True)\n",
        "    return np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
        "\n",
        "def relu_backward(Z, delta):\n",
        "    delta[Z == 0] = 0\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t * np.log(y + 1e-7) / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FullyConnectedNeuralNetwork():\n",
        "    def __init__(self, layer_units):\n",
        "        '''\n",
        "        layer_units: list, 各層のノード数を格納したリスト\n",
        "        '''\n",
        "        self.n_iter = 0\n",
        "        self.t_ = 0\n",
        "        self.layer_units = layer_units\n",
        "        self.n_layers_ = len(layer_units)\n",
        "\n",
        "        # パラメータの初期化\n",
        "        self.coefs_ = []\n",
        "        self.intercepts_ = []\n",
        "        for i in range(self.n_layers_ - 1):\n",
        "            # coef_init, intercept_init = self._init_coef(( ア ))\n",
        "            coef_init, intercept_init = self._init_coef(layer_units[i], layer_units[i + 1])\n",
        "            self.coefs_.append(coef_init)\n",
        "            self.intercepts_.append(intercept_init)\n",
        "        \n",
        "        # 勾配の初期化\n",
        "        self.coef_grads_ = [np.empty((n_in_, n_out_)) for n_in_, n_out_ in zip(layer_units[:-1], layer_units[1:])]\n",
        "        self.intercept_grads_ = [np.empty(n_out_) for n_out_ in layer_units[1:]]\n",
        "    \n",
        "    def _init_coef(self, n_in, n_out):\n",
        "        '''\n",
        "        ある層間のパラメータを初期化するメソッド\n",
        "        n_in: int, 入力側のノード数\n",
        "        n_out: int, 出力側のノード数\n",
        "        '''\n",
        "        std = np.sqrt(2 / n_in)\n",
        "        coef_init = np.random.randn(n_in, n_out) * std\n",
        "        intercept_init = np.zeros(n_out)\n",
        "        return coef_init, intercept_init\n",
        "    \n",
        "    def _forward(self, activations):\n",
        "        '''\n",
        "        順伝播処理を行うメソッド\n",
        "        activartions: list, 各層の出力を納めたリスト\n",
        "                     activation[0]は入力データ\n",
        "                     activation[i].shape=(バッチサイズ、ノード数)\n",
        "        '''\n",
        "        affine = [None] * (self.n_layers_ - 1)\n",
        "        for i in range(self.n_layers_ - 1):\n",
        "            # アフィン変換\n",
        "            affine[i] = np.dot(activations[i], self.coefs_[i]) + self.intercepts_[i]\n",
        "\n",
        "            # if (i + 1) == (( イ )):\n",
        "            if (i + 1) == (self.n_layers_ - 1):\n",
        "                '''\n",
        "                出力層の場合\n",
        "                '''\n",
        "                activations[i + 1] = softmax(affine[i])\n",
        "            else:\n",
        "                '''\n",
        "                隠れ層の場合\n",
        "                '''\n",
        "                activations[i + 1] = relu(affine[i])\n",
        "\n",
        "        return activations\n",
        "    \n",
        "    def _grad(self, j, activations, deltas):\n",
        "        '''\n",
        "        各パラメータの勾配を算出するメソッド\n",
        "        j: int, アフィンの番号\n",
        "        activations: list, 各層の出力を納めたメソッド\n",
        "        deltas: list, 出力層側から伝わってきた勾配を納めたリスト\n",
        "        '''\n",
        "        # self.coef_grads_[j] = ( ウ )\n",
        "        self.coef_grads_[j] = np.dot(activations[j].T, deltas[j])\n",
        "        # self.intercept_grads_[j] = ( エ )\n",
        "        self.intercept_grads_[j] = np.sum(deltas[j], axis=0)\n",
        "    \n",
        "    def _backward(self, t, activations):\n",
        "        '''\n",
        "        逆伝播処理を行うメソッド\n",
        "        t: array-like, 正解ラベル, t.shape=(バッチサイズ、出力層ノード数)\n",
        "        activations: list, 各層の出力を納めたリスト\n",
        "        '''\n",
        "        deltas = [None] * (self.n_layers_ - 1)\n",
        "        last = self.n_layers_ - 2\n",
        "    \n",
        "        # 交差エントロピー誤差とソフトマックス関数を合わせて勾配を算出\n",
        "        n_samples = t.shape[0]\n",
        "        # deltas[last] = ( オ )\n",
        "        deltas[last] = (activations[-1] - t) / n_samples\n",
        "\n",
        "        # 出力層の1つ手前のパラメータの勾配を算出\n",
        "        # self._grad(( カ ), activations, deltas)\n",
        "        self._grad(last, activations, deltas)\n",
        "\n",
        "        # 残りのパラメータの勾配を算出\n",
        "        for i in range(self.n_layers_ - 2, 0, -1):\n",
        "            # 入力(activations)の勾配を算出\n",
        "            # deltas[i - 1] = ( キ )\n",
        "            deltas[i - 1] = np.dot(deltas[i], self.coefs_[i].T)\n",
        "\n",
        "            # 活性化関数ReLuの勾配を算出\n",
        "            # relu_backward(( ク ), deltas[i - 1])\n",
        "            relu_backward(activations[i], deltas[i - 1])\n",
        "\n",
        "            # パラメータの勾配を算出\n",
        "            # self._grad(( ケ ), activations, deltas)\n",
        "            self._grad(i - 1, activations, deltas)\n",
        "        \n",
        "        return\n",
        "    \n",
        "    def _forward_and_backward(self, x, t):\n",
        "        '''\n",
        "        順伝播処理を実行した後、逆伝播処理を実行するメソッド\n",
        "        x: array-like, 入力データ, x.shape=(バッチサイズ、入力層ノード数)\n",
        "        t: array-like, 正解ラベル, t.shape=(バッチサイズ、出力層ノード数)\n",
        "        '''\n",
        "        activations = [x] + [None] * (self.n_layers_ - 1)\n",
        "\n",
        "        # 順伝播\n",
        "        activations = self._forward(activations)\n",
        "        loss = cross_entropy_error(activations[-1], t)\n",
        "\n",
        "        # 逆伝播\n",
        "        self._backward(t, activations)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "WMY_ZbPT2MMH"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 4\n",
        "hidden_size = 5\n",
        "output_size = 3\n",
        "model = FullyConnectedNeuralNetwork([input_size, hidden_size, output_size])"
      ],
      "metadata": {
        "id": "6IIOIKFIUPjS"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.coef_grads_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGxW4YluUZz2",
        "outputId": "eda1d541-89d4-4954-9c90-ead617542841"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.69807499, -0.7039001 , -0.24161202, -0.64442406, -0.90971141],\n",
              "        [ 0.03167245,  0.300309  , -0.91035939,  0.30489739, -0.98991501],\n",
              "        [ 0.15885928, -0.93877761,  0.41244743, -0.26122254, -0.42368744],\n",
              "        [-0.09389548, -0.43755282, -0.44632541, -1.43483421,  0.54631262]]),\n",
              " array([[ 0.5306221 ,  1.02066049,  0.52098645],\n",
              "        [ 1.09989768,  1.8157602 ,  1.64059741],\n",
              "        [-0.63043139, -0.39035527,  0.73134284],\n",
              "        [ 0.05149311,  0.71845009,  0.8621749 ],\n",
              "        [ 1.03280966,  1.31582013, -0.57742054]])]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.intercept_grads_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crs9GQYyUfUN",
        "outputId": "ce729079-f613-4440-d1fc-a69693e139c5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3.6563664e-316, 0.0000000e+000, 0.0000000e+000, 0.0000000e+000,\n",
              "        0.0000000e+000]),\n",
              " array([3.85156186e-316, 2.14465755e-316, 3.65634506e-316])]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "x = np.random.randn(batch_size, input_size)\n",
        "t = np.random.randn(batch_size, output_size)"
      ],
      "metadata": {
        "id": "21BMzNheU3qF"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model._forward_and_backward(x, t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXS7DrS5Uo_k",
        "outputId": "b1d35882-a4c7-4a15-e391-f7fc8597a040"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.08504708986421507"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ]
}